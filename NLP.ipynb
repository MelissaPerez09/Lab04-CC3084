{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 04 - Procesamiento de Lenguaje Natural (NLP)\n",
    "\n",
    "Integrantes:\n",
    "- José Pablo Kiesling Lange, 21581\n",
    "- Melissa Pérez Alarcón, 21385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Embedding, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importación de datos\n",
    "- Utilice el conjunto de datos IMDB proporcionado por Keras. pero esta vez, en lugar de utilizar sólo las 20.000 palabras más frecuentes, utilice las 50.000 palabras más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 25000\n",
      "Tamaño del conjunto de prueba: 25000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=50000)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(x_train)}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-procesamiento\n",
    "- Secuencie y rellene las críticas para que todas tengan una longitud uniforme.\n",
    "- De las críticas, extraiga características (features) adicionales, por ejemplo. la longitud de la crítica, la proporción de palabras positivas/negativas y cualquier otra que considere pueda ser útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitud máxima de las secuencias\n",
    "max_length = 500\n",
    "\n",
    "# Relleno de las secuencias para que todas tengan la misma longitud\n",
    "x_train_padded = pad_sequences(x_train, maxlen=max_length, padding='post')\n",
    "x_test_padded = pad_sequences(x_test, maxlen=max_length, padding='post')\n",
    "\n",
    "print(f\"Tamaño de las secuencias de entrenamiento: {x_train_padded.shape}\")\n",
    "print(f\"Tamaño de las secuencias de prueba: {x_test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "def calculate_word_ratios(text_sequence, positive_words, negative_words):\n",
    "    pos_count = neg_count = total_count = 0\n",
    "    for word_index in text_sequence:\n",
    "        word = imdb.get_word_index().get(word_index, \"\")\n",
    "        if word in positive_words:\n",
    "            pos_count += 1\n",
    "        if word in negative_words:\n",
    "            neg_count += 1\n",
    "        total_count += 1\n",
    "    if total_count == 0:\n",
    "        return (0, 0)\n",
    "    return (pos_count / total_count, neg_count / total_count)\n",
    "\n",
    "# Ejemplo de palabras positivas y negativas\n",
    "positive_words = ['good', 'great', 'best', 'amazing', 'excellent', 'love']\n",
    "negative_words = ['bad', 'worst', 'terrible', 'awful', 'horrible', 'hate']\n",
    "\n",
    "# Aplicar la función a cada secuencia\n",
    "train_ratios = [calculate_word_ratios(seq, positive_words, negative_words) for seq in x_train]\n",
    "test_ratios = [calculate_word_ratios(seq, positive_words, negative_words) for seq in x_test]\n",
    "\n",
    "# Convertir a numpy arrays\n",
    "train_ratios_np = np.array(train_ratios)\n",
    "test_ratios_np = np.array(test_ratios)\n",
    "\n",
    "print(f\"Características adicionales del conjunto de entrenamiento: {train_ratios_np.shape}\")\n",
    "print(f\"Características adicionales del conjunto de prueba: {test_ratios_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modelo\n",
    "- Cree un modelo LSTM que acepte las características (features) adicionales junto con la secuencia de palabras.\n",
    "- Intente usar una arquitectura más compleja, incorporando más capas LSTM, capas de Dropout para la regularización y tal vez alguna capa densamente conectada después de la LSTM. (ver también la referencia al final de este documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la entrada para las secuencias de palabras\n",
    "word_input = Input(shape=(max_length,), dtype='int32', name='word_input')\n",
    "\n",
    "# Definir la entrada para las características adicionales\n",
    "feature_input = Input(shape=(train_ratios_np.shape[1],), name='feature_input')\n",
    "\n",
    "# Capa de embedding para las palabras\n",
    "embedded_sequences = Embedding(input_dim=50000, output_dim=128, input_length=max_length)(word_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM y Dropout\n",
    "lstm_out = LSTM(64, return_sequences=True)(embedded_sequences)\n",
    "lstm_out = Dropout(0.5)(lstm_out)\n",
    "lstm_out = LSTM(64)(lstm_out)\n",
    "lstm_out = Dropout(0.5)(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar las salidas de las capas con las características adicionales\n",
    "combined = concatenate([lstm_out, feature_input])\n",
    "\n",
    "# Añadir capas densas\n",
    "dense_out = Dense(64, activation='relu')(combined)\n",
    "dense_out = Dropout(0.5)(dense_out)\n",
    "output = Dense(1, activation='sigmoid')(dense_out)  # Salida binaria para análisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[word_input, feature_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrenamiento y Evaluación\n",
    "- Entrene su modelo con el conjunto de datos de entrenamiento y evalúe su desempeño con el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
